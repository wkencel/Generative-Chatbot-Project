{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd687ec5-5dfa-47ca-b13f-8734bfce0614",
   "metadata": {},
   "source": [
    "# ChatBot Final Project: Team 7 #\n",
    "\n",
    "Gurleen Virk, Jay Patel, and Will Kencel\n",
    "\n",
    "October 21, 2024\n",
    "\n",
    "Professor Kahila Mokhtari Jadid\n",
    "\n",
    "AAI: NLP520"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e58aec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "905b2475-5363-43e6-a087-46736dbf766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6257207d-b663-4d54-ad2b-90d826098b50",
   "metadata": {},
   "source": [
    "## Load Data & Text Pre-Processing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "beaf82f5-ec27-4aee-9759-2ada89c9a97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load movie line from local directory (remember to change to YOUR file location)\n",
    "with open('/Users/gurl/Documents/AAI520_NLP/CornellData/movie_lines.txt', 'r', encoding='utf-8', errors='replace') as file:\n",
    "    lines = pd.read_table(file, sep='\\t', header=None, on_bad_lines='skip')\n",
    "\n",
    "# load conversation file from github (no need to change anything here for data to load)\n",
    "convolines = pd.read_table('https://raw.githubusercontent.com/wkencel/Generative-Chatbot-Project/refs/heads/main/movie_conversations.txt', sep='\\t', header=None, encoding='utf-8', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "940171b4-c1f0-45f9-8607-f9bc442f945c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON ++...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++...\n",
       "1  L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON ++...\n",
       "2  L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$...\n",
       "3  L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++...\n",
       "4  L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$...\n",
       "5  L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++...\n",
       "6  L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$...\n",
       "7  L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++...\n",
       "8  L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$...\n",
       "9  L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$..."
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view lines\n",
    "lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "24c1733a-c43c-45aa-b404-e50c164ab6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L271', 'L27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L276', 'L277']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L280', 'L281']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L363', 'L364']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L365', 'L366']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L19...\n",
       "1  u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\n",
       "2  u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L20...\n",
       "3  u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L20...\n",
       "4  u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\n",
       "5  u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L271', 'L27...\n",
       "6  u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L276', 'L277']\n",
       "7  u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L280', 'L281']\n",
       "8  u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L363', 'L364']\n",
       "9  u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L365', 'L366']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f7afb729-e70b-4d6e-9efe-c9cd568c8ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to map each line's id with its text\n",
    "id2line = {}\n",
    "\n",
    "# Iterate over each row in the dataframe and access the text data\n",
    "for line in lines[0]:  # Access the first column which contains the movie lines\n",
    "    _line = line.split(' +++$+++ ')\n",
    "    if len(_line) == 5:\n",
    "        id2line[_line[0]] = _line[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9ea14c67-65f3-4207-ad3f-7b8d57f5c4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1045: They do not!\n",
      "L1044: They do to!\n",
      "L985: I hope so.\n",
      "L984: She okay?\n",
      "L925: Let's go.\n",
      "L924: Wow\n",
      "L872: Okay -- you're gonna need to learn how to lie.\n",
      "L871: No\n",
      "L870: I'm kidding.  You know how sometimes you just become this \"persona\"?  And you don't know how to quit?\n",
      "L869: Like my fear of wearing pastels?\n"
     ]
    }
   ],
   "source": [
    "# Print the first 10 entries\n",
    "for i, (key, value) in enumerate(id2line.items()):\n",
    "    if i < 10:  # Change this number to see more or fewer entries\n",
    "        print(f\"{key}: {value}\")\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "57b6babe-7c43-47fb-be05-b87ebe0c1e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all of the conversations' lines' ids\n",
    "convs = []\n",
    "for index, row in convolines.iterrows():\n",
    "    line = row[0]  # Access the first column of the row\n",
    "    _line = line.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \"\").replace(\" \", \"\")\n",
    "    convs.append(_line.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7562a6e4-9804-49c9-a618-2648313cc238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['L194', 'L195', 'L196', 'L197'],\n",
       " ['L198', 'L199'],\n",
       " ['L200', 'L201', 'L202', 'L203'],\n",
       " ['L204', 'L205', 'L206'],\n",
       " ['L207', 'L208'],\n",
       " ['L271', 'L272', 'L273', 'L274', 'L275'],\n",
       " ['L276', 'L277'],\n",
       " ['L280', 'L281'],\n",
       " ['L363', 'L364'],\n",
       " ['L365', 'L366']]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first 10 entries\n",
    "convs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c4b2e80e-7746-4565-9341-c10fb179a2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the sentences: inputs (questions) and targets (answers)\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for conv in convs:\n",
    "    for i in range(len(conv) - 1):\n",
    "        if conv[i] in id2line and conv[i + 1] in id2line:\n",
    "            questions.append(id2line[conv[i]])\n",
    "            answers.append(id2line[conv[i + 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a2fd7636-afb2-40f3-a3e7-96531ebfda1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions: 221416\n",
      "Number of answers: 221416\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of questions:\", len(questions))\n",
    "print(\"Number of answers:\", len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "adb0916d-1be0-4048-a3d1-fdb56c3c6be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\n",
      "Well, I thought we'd start with pronunciation, if that's okay with you.\n",
      "\n",
      "Well, I thought we'd start with pronunciation, if that's okay with you.\n",
      "Not the hacking and gagging and spitting part.  Please.\n",
      "\n",
      "Not the hacking and gagging and spitting part.  Please.\n",
      "Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\n",
      "\n",
      "You're asking me out.  That's so cute. What's your name again?\n",
      "Forget it.\n",
      "\n",
      "No, no, it's my fault -- we didn't have a proper introduction ---\n",
      "Cameron.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if data is loaded correctly\n",
    "limit = 0\n",
    "for i in range(limit, limit+5):\n",
    "    print(questions[i])\n",
    "    print(answers[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "da0bae36-6d3c-48d2-ab35-4c5201d6de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from questions and answers\n",
    "data = {'Questions': questions, 'Answers': answers}\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "95184672-de6d-4def-85d8-89f7502a0e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can we make this quick?  Roxanne Korrine and A...</td>\n",
       "      <td>Well, I thought we'd start with pronunciation,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, I thought we'd start with pronunciation,...</td>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "      <td>Okay... then how 'bout we try out some French ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You're asking me out.  That's so cute. What's ...</td>\n",
       "      <td>Forget it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No, no, it's my fault -- we didn't have a prop...</td>\n",
       "      <td>Cameron.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Questions  \\\n",
       "0  Can we make this quick?  Roxanne Korrine and A...   \n",
       "1  Well, I thought we'd start with pronunciation,...   \n",
       "2  Not the hacking and gagging and spitting part....   \n",
       "3  You're asking me out.  That's so cute. What's ...   \n",
       "4  No, no, it's my fault -- we didn't have a prop...   \n",
       "\n",
       "                                             Answers  \n",
       "0  Well, I thought we'd start with pronunciation,...  \n",
       "1  Not the hacking and gagging and spitting part....  \n",
       "2  Okay... then how 'bout we try out some French ...  \n",
       "3                                         Forget it.  \n",
       "4                                           Cameron.  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2e32a9b3-4cc4-474e-be7c-b3b4162a4adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221416, 2)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b33a847f-d179-485b-903a-dab797705855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "data.drop_duplicates(inplace  = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7d26b62c-a857-4e0e-ba41-6f7837689779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220021, 2)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a9e7cbe4-91c5-4962-b2eb-edec7cfd223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for cleaning the text: lowercase, remove punctuations, and replace certain words\n",
    "\n",
    "def clean_text(text):\n",
    "    '''Clean text by removing unnecessary characters and altering the format of words.'''\n",
    "\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"there's\", \"there is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"n'\", \"ng\", text)\n",
    "    text = re.sub(r\"'bout\", \"about\", text)\n",
    "    text = re.sub(r\"'til\", \"until\", text)\n",
    "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5b44bf18-7d58-41bb-a096-e514a01b5b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can we make this quick  roxanne korrine and an...</td>\n",
       "      <td>well i thought we would start with pronunciati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>well i thought we would start with pronunciati...</td>\n",
       "      <td>not the hacking and gagging and spitting part ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not the hacking and gagging and spitting part ...</td>\n",
       "      <td>okay then how about we try out some french cui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you are asking me out  that is so cute what is...</td>\n",
       "      <td>forget it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no no it is my fault  we did not have a proper...</td>\n",
       "      <td>cameron</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Questions  \\\n",
       "0  can we make this quick  roxanne korrine and an...   \n",
       "1  well i thought we would start with pronunciati...   \n",
       "2  not the hacking and gagging and spitting part ...   \n",
       "3  you are asking me out  that is so cute what is...   \n",
       "4  no no it is my fault  we did not have a proper...   \n",
       "\n",
       "                                             Answers  \n",
       "0  well i thought we would start with pronunciati...  \n",
       "1  not the hacking and gagging and spitting part ...  \n",
       "2  okay then how about we try out some french cui...  \n",
       "3                                          forget it  \n",
       "4                                            cameron  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function to the DataFrame\n",
    "data['Questions'] = data['Questions'].apply(clean_text)\n",
    "data['Answers'] = data['Answers'].apply(clean_text)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1d8646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# added data augmentation with synonyms\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Data Augmentation using Synonym Replacement\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def synonym_replacement(sentence, n):\n",
    "    words = sentence.split()\n",
    "    new_words = words.copy()\n",
    "    random_word_list = list(set([word for word in words if wordnet.synsets(word)]))\n",
    "    random.shuffle(random_word_list)\n",
    "\n",
    "    num_replaced = 0\n",
    "    for random_word in random_word_list:\n",
    "        synonyms = list(set([syn.name().split('.')[0] for syn in wordnet.synsets(random_word)]))\n",
    "        if len(synonyms) >= 1:\n",
    "            synonym = random.choice(synonyms)\n",
    "            new_words = [synonym if word == random_word else word for word in new_words]\n",
    "            num_replaced += 1\n",
    "        if num_replaced >= n:\n",
    "            break\n",
    "\n",
    "    sentence = ' '.join(new_words)\n",
    "    return sentence\n",
    "\n",
    "# Augment the dataset\n",
    "augmented_questions = data['Questions'].apply(lambda x: synonym_replacement(x, 2))\n",
    "augmented_answers = data['Answers'].apply(lambda x: synonym_replacement(x, 2))\n",
    "\n",
    "# Combine original and augmented data\n",
    "data['Questions'] = pd.concat([data['Questions'], augmented_questions], ignore_index=True)\n",
    "data['Answers'] = pd.concat([data['Answers'], augmented_answers], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ee79d28a-25f3-4de7-9988-95ff13bccbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More text pre-processing\n",
    "import string\n",
    "\n",
    "exclude = set(string.punctuation)\n",
    "remove_digits = str.maketrans('', '', string.digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ab88aed3-9e53-4f71-8022-5918dc9f4bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More text pre-processing\n",
    "def preprocess_questions_sentences(sent):\n",
    "    '''Function to preprocess English Sentence'''\n",
    "    sent = sent.lower()\n",
    "    sent = sent.replace(\"'\", '') \n",
    "    sent = ''.join(ch for ch in sent if ch not in exclude)\n",
    "    sent = sent.translate(remove_digits)\n",
    "    \n",
    "    sent = sent.strip()\n",
    "    sent = re.sub(\" +\", \" \", sent)\n",
    "    return sent\n",
    "\n",
    "\n",
    "# include SOS (start of sent.) & EOS (end of sent.) tokens\n",
    "def preprocess_answer_sentence(sent):\n",
    "    if isinstance(sent, str):\n",
    "        sent = sent.lower()\n",
    "        sent = sent.replace(\"'\", '')\n",
    "        sent = ''.join(ch for ch in sent if ch not in exclude)\n",
    "        sent = sent.translate(remove_digits)\n",
    "        sent = sent.strip()\n",
    "        sent = re.sub(\" +\", \" \", sent)\n",
    "        sent = \"startseq \" + sent + \" endseq\" \n",
    "        return sent\n",
    "    else:\n",
    "        \n",
    "        return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a3970d83-0c37-477a-973d-41fd0f0a9bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can we make this quick roxanne korrine and and...</td>\n",
       "      <td>startseq well i thought we would start with pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>well i thought we would start with pronunciati...</td>\n",
       "      <td>startseq not the hacking and gagging and spitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not the hacking and gagging and spitting part ...</td>\n",
       "      <td>startseq okay then how about we try out some f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you are asking me out that is so cute what is ...</td>\n",
       "      <td>startseq forget it endseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no no it is my fault we did not have a proper ...</td>\n",
       "      <td>startseq cameron endseq</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Questions  \\\n",
       "0  can we make this quick roxanne korrine and and...   \n",
       "1  well i thought we would start with pronunciati...   \n",
       "2  not the hacking and gagging and spitting part ...   \n",
       "3  you are asking me out that is so cute what is ...   \n",
       "4  no no it is my fault we did not have a proper ...   \n",
       "\n",
       "                                             Answers  \n",
       "0  startseq well i thought we would start with pr...  \n",
       "1  startseq not the hacking and gagging and spitt...  \n",
       "2  startseq okay then how about we try out some f...  \n",
       "3                          startseq forget it endseq  \n",
       "4                            startseq cameron endseq  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocess function on data\n",
    "data['Questions'] = data['Questions'].apply(preprocess_questions_sentences)\n",
    "data['Answers'] = data['Answers'].apply(preprocess_answer_sentence)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "45c2f12b-7a91-4fbe-b30c-ee60ab5424f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove questions and answers shorter than 1 word and longer than 20 words\n",
    "min_line_length = 1\n",
    "max_line_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "de6d6754-3d2e-4522-8ae2-49cc0b4bed90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>well i thought we would start with pronunciati...</td>\n",
       "      <td>startseq not the hacking and gagging and spitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not the hacking and gagging and spitting part ...</td>\n",
       "      <td>startseq okay then how about we try out some f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you are asking me out that is so cute what is ...</td>\n",
       "      <td>startseq forget it endseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no no it is my fault we did not have a proper ...</td>\n",
       "      <td>startseq cameron endseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gosh if only we could find kat a boyfriend</td>\n",
       "      <td>startseq let me see what i can do endseq</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Questions  \\\n",
       "1  well i thought we would start with pronunciati...   \n",
       "2  not the hacking and gagging and spitting part ...   \n",
       "3  you are asking me out that is so cute what is ...   \n",
       "4  no no it is my fault we did not have a proper ...   \n",
       "9         gosh if only we could find kat a boyfriend   \n",
       "\n",
       "                                             Answers  \n",
       "1  startseq not the hacking and gagging and spitt...  \n",
       "2  startseq okay then how about we try out some f...  \n",
       "3                          startseq forget it endseq  \n",
       "4                            startseq cameron endseq  \n",
       "9           startseq let me see what i can do endseq  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a function to count the number of words in a text\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "# Filter the DataFrame\n",
    "filtered_data = data[\n",
    "    (data['Questions'].apply(count_words).between(min_line_length, max_line_length)) &\n",
    "    (data['Answers'].apply(count_words).between(min_line_length, max_line_length))\n",
    "]\n",
    "\n",
    "# Update the original DataFrame\n",
    "data = filtered_data\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "54589589-6088-490e-93de-599b03e63ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160580\n",
      "160580\n",
      "\n",
      "Question 1: there\n",
      "Answer 1: startseq where endseq\n",
      "\n",
      "Question 2: hi\n",
      "Answer 2: startseq looks like things worked out tonight huh endseq\n",
      "\n",
      "Question 3: but\n",
      "Answer 3: startseq you always been this selfish endseq\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort Qs and As by length of questions to reduce amount of padding during training\n",
    "# Hope to speed up training and reduce the loss\n",
    "\n",
    "# Convert questions and answers to their respective lengths\n",
    "data['Question_Length'] = data['Questions'].apply(lambda x: len(x.split()))\n",
    "data['Answer_Length'] = data['Answers'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Sort Qs and As by length of questions\n",
    "sorted_questions = []\n",
    "sorted_answers = []\n",
    "\n",
    "for length in range(1, max_line_length + 1):\n",
    "    for index, row in data.iterrows():\n",
    "        if row['Question_Length'] == length:\n",
    "            sorted_questions.append(row['Questions'])\n",
    "            sorted_answers.append(row['Answers'])\n",
    "\n",
    "# Output the results\n",
    "print(len(sorted_questions))\n",
    "print(len(sorted_answers))\n",
    "print()\n",
    "for i in range(min(3, len(sorted_questions))):  # Use min to avoid index errors\n",
    "    print(f\"Question {i + 1}: {sorted_questions[i]}\")\n",
    "    print(f\"Answer {i + 1}: {sorted_answers[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2f04d87a-f47b-4d83-8f50-f9979f44c93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "      <th>Question_Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ryan</td>\n",
       "      <td>startseq i am sure you understand endseq</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exactly</td>\n",
       "      <td>startseq then a sympathetic mouth then a sympa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no</td>\n",
       "      <td>startseq you came because it is taking over yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lydia</td>\n",
       "      <td>startseq and lydia telling natalie the truth m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jerry</td>\n",
       "      <td>startseq listen to me endseq</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Questions                                            Answers  \\\n",
       "0      ryan           startseq i am sure you understand endseq   \n",
       "1   exactly  startseq then a sympathetic mouth then a sympa...   \n",
       "2        no  startseq you came because it is taking over yo...   \n",
       "3     lydia  startseq and lydia telling natalie the truth m...   \n",
       "4     jerry                       startseq listen to me endseq   \n",
       "\n",
       "   Question_Length  \n",
       "0                1  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  \n",
       "4                1  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the DataFrame by question length\n",
    "data = data.sort_values(by='Question_Length')\n",
    "\n",
    "# Reset index if needed\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Output the sorted DataFrame\n",
    "data[['Questions', 'Answers', 'Question_Length']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f933cd67-42d6-456e-87c7-76a378f8f079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160580, 4)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b1f433-2c11-4b47-95c5-0de65ef58252",
   "metadata": {},
   "source": [
    "### Vectorizing text ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8d8a3180-95e7-406f-b4f8-8c46b6994d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame columns to lists\n",
    "q_sentences = data['Questions'].tolist()\n",
    "a_sentences = data['Answers'].tolist()\n",
    "\n",
    "# Define the split ratios\n",
    "train_ratio = 0.80  # 80% for training\n",
    "val_ratio = 0.10    # 10% for validation\n",
    "test_ratio = 0.10   # 10% for testing\n",
    "\n",
    "# Ensure the sum of ratios equals 1\n",
    "assert train_ratio + val_ratio + test_ratio == 1.0, \"Split ratios must sum to 1.\"\n",
    "\n",
    "# Split into training and temporary sets (which will later be split into validation and test)\n",
    "train_q_sents, temp_q_sents, train_a_sents, temp_a_sents = train_test_split(\n",
    "    q_sentences, a_sentences, test_size=(1 - train_ratio), random_state=42, shuffle=True)\n",
    "\n",
    "# Now split the temporary set into validation and test sets\n",
    "val_size = val_ratio / (val_ratio + test_ratio)  # Calculate validation size relative to temp set\n",
    "val_q_sents, test_q_sents, val_a_sents, test_a_sents = train_test_split(\n",
    "    temp_q_sents, temp_a_sents, test_size=val_size, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bad4c868-4697-48bb-a29c-a3f6651f18c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Vocabulary Size: 32642\n",
      "Answer Vocabulary Size: 31517\n"
     ]
    }
   ],
   "source": [
    "# VOCABULARY\n",
    "# Filter out non-string elements from training sets\n",
    "train_q_sents = [str(sent) for sent in train_q_sents]\n",
    "train_a_sents = [str(sent) for sent in train_a_sents]\n",
    "\n",
    "# Tokenize question sentences\n",
    "ques_tokenizer = Tokenizer(oov_token='<OOV>')\n",
    "ques_tokenizer.fit_on_texts(train_q_sents)\n",
    "ques_vocab_size = len(ques_tokenizer.word_index) + 1\n",
    "\n",
    "# Tokenize answer sentences\n",
    "ans_tokenizer = Tokenizer()\n",
    "ans_tokenizer.fit_on_texts(train_a_sents)\n",
    "ans_vocab_size = len(ans_tokenizer.word_index) + 1\n",
    "\n",
    "print(f\"Question Vocabulary Size: {ques_vocab_size}\\nAnswer Vocabulary Size: {ans_vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5083d101-39bd-4da9-ad33-cbe87c46a476",
   "metadata": {},
   "source": [
    "The code prepares question and answer sentences for further processing by converting them to strings, creating tokenizers to build vocabularies, and calculating the vocabulary sizes for both questions and answers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f3aa5975-66bb-4e2c-9fa8-58cbea8babcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 30\n",
    "\n",
    "# Convert text to sequences\n",
    "ques_sequences = ques_tokenizer.texts_to_sequences(train_q_sents)\n",
    "ans_sequences = ans_tokenizer.texts_to_sequences(train_a_sents)\n",
    "\n",
    "# Pad sequences\n",
    "source_seqs = pad_sequences(ques_sequences, maxlen=max_length, padding='post')\n",
    "target_seqs = pad_sequences(ans_sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d12d4f79-dc6b-4362-b04e-b173ed159d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((source_seqs, target_seqs))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(source_seqs)).batch(16, drop_remainder=True)\n",
    "\n",
    "# Create validation dataset\n",
    "val_sequences = ques_tokenizer.texts_to_sequences(val_q_sents)\n",
    "val_sequences = pad_sequences(val_sequences, maxlen=max_length, padding='post')\n",
    "val_target_sequences = ans_tokenizer.texts_to_sequences(val_a_sents)\n",
    "val_target_sequences = pad_sequences(val_target_sequences, maxlen=max_length, padding='post')\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_sequences, val_target_sequences))\n",
    "val_dataset = val_dataset.batch(16, drop_remainder=True)\n",
    "\n",
    "# Create test dataset\n",
    "test_sequences = ques_tokenizer.texts_to_sequences(test_q_sents)\n",
    "test_sequences = pad_sequences(test_sequences, maxlen=max_length, padding='post')\n",
    "test_target_sequences = ans_tokenizer.texts_to_sequences(test_a_sents)\n",
    "test_target_sequences = pad_sequences(test_target_sequences, maxlen=max_length, padding='post')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_sequences, test_target_sequences))\n",
    "test_dataset = test_dataset.batch(16, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9d059b7a-d1c7-4a63-a96d-0ed871d8a449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 128464\n",
      "Validation set size: 16058\n",
      "Test set size: 16058\n"
     ]
    }
   ],
   "source": [
    "# Print sizes of the datasets\n",
    "print(f\"Training set size: {len(train_q_sents)}\")\n",
    "print(f\"Validation set size: {len(val_q_sents)}\")\n",
    "print(f\"Test set size: {len(test_q_sents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a95a992-0103-470b-bb55-2ae0af888f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530882aa-239e-402f-9d1c-bb17c397a02c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
